\documentclass{article}
\usepackage[utf8]{inputenc}

\title{MAT257 Notes}
\author{Jad Elkhaleq Ghalayini}
\date{April 2019}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{cancel}
\usepackage{xcolor}

\usepackage[margin=1in]{geometry}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem*{corollary}{Corollary}
\newtheorem{exercise}{Exercise}
\newtheorem{claim}{Claim}
\newtheorem{proposition}{Proposition}

\DeclareMathOperator{\Int}{Int}
\DeclareMathOperator{\grad}{grad}
\DeclareMathOperator{\Div}{div}
\DeclareMathOperator{\curl}{curl}
\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\Ima}{Im}
\DeclareMathOperator{\Vol}{vol}
\DeclareMathOperator{\D}{D}

\newcommand{\reals}[0]{\mathbb{R}}
\newcommand{\nats}[0]{\mathbb{N}}
\newcommand{\ints}[0]{\mathbb{Z}}
\newcommand{\rationals}[0]{\mathbb{Q}}
\newcommand{\brac}[1]{\left(#1\right)}
\newcommand{\sbrac}[1]{\left[#1\right]}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\eval}[3]{\left.#3\right|_{#1}^{#2}}
\newcommand{\ip}[2]{\left\langle#1,#2\right\rangle}
\newcommand{\prt}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\hlfspc}[0]{\mathbb{H}}
\newcommand{\loint}[0]{\operatorname{L}\int}
\newcommand{\hiint}[0]{\operatorname{U}\int}
\newcommand{\indic}[1]{\chi_{#1}}

\newcommand{\TODO}[1]{\textcolor{red}{\textbf{TODO:} #1}}


\begin{document}

\maketitle

This document is a collection of notes for the course MAT257: Analysis II, as taught by Professor Edward Bierstone in 2018 at the University of Toronto. The notes are a combination of notes I made in class (which can be found in their original form in the \verb|notes| folder in this repository) and scans of handwritten notes which Professor Bierstone has generously given me the permission to use.

\section{Introduction}

\TODO{this}

\section{Differentiation}

\TODO{this}

\section{Integration}

\subsection{The (Riemann) Integral Over a Rectangle}

\TODO{this}

\subsection{Integrals Over More General Bounded Sets}

\TODO{this}

\subsection{Fubini's Theorem}

\TODO{rewrite}

We are now going to talk about Fubini's theorem, which is about how to integrate over a high-dimensional rectangle by repeatedly performing individual integrals. Let's start with an example. Suppose we want to integrate over a rectangle
\begin{equation}
  A = [a, b] \times [c, d] \subseteq \reals^2
\end{equation}
and let's suppose, to make it easy, we have a continuous, non-negative function \(f\), defined on this rectangle, say
\begin{equation}
  z = f(x, y) \geq 0
\end{equation}
The idea is that if we fix a point on the \(x\)-axis, say \(x\), we can consider the ``slice'' in the \(y\)-direction determined by this point. We could find, for example, the area of that slice, and it's reasonable to expect that the integral of \(f\) on the rectangle, we could obtain by integrating the area of that slice along the length of the rectangle.

The idea then is to try to find the area of such a slice, which would be in this case, for some \(x\),
\begin{equation}
  h(x) = \int_c^dg_x(y)dy = \int_c^df(x, y)dy
\end{equation}
where \(g_x(y) = f(x, y)\) fixing \(x\). It's reasonable to expect that
\begin{equation}
  \int_Af = \int_a^bh = \int_a^b\left(\int_c^df(x, y)dy\right)dx
\end{equation}
So that's the idea of Fubini's theorem: that we should be able to integrate a function over a rectangle by repeated one-dimensional integrals. Of course, we're not interested in integrating only continuous functions, we want to look at more general, integrable functions, but if you think about that, supposing \(f\) is integrable, this could run into a problem: one of the functions \(g_x\) might not be integrable on \([c, d]\). After all, it's set of discontinuities could be \(x_0 \times [c, d]\) for some \(x_0\), so \(\int_c^dg_{x_0}\) makes no sense!

So we'll have to formulate something maybe a little bit more technical, but it's to capture that problem. Suppose we just have \(f: A \to \reals\) bounded. The function may or may not be integrable, meaning the supremum of lower sums is equal to the infimum of lower sums. Whether the function is integrable or not, we can still look at the supermum of lower sums and the infimum of lower sums, which is what we'll do.

We'll define the \underline{lower} and \underline{upper integrals} of \(f\) on \(A\), \(\loint_Af\) and \(\hiint_Af\) respectively, to be the supremum of all the lower sums \(L(f, \mc{P})\) and infimum of all the upper sums \(U(f, \mc{P})\) respectively. We can now write down our theorem as the previous formula, but taking into account that we don't know that the function \(g_x\) mentioned before, we just replace it by the lower or upper integral:
\begin{theorem}
  Suppose \(A \subset \reals^m\) and \(B \subset \reals^n\) are closed rectangles and \(f: A \times B \to \reals\) is integrable. For all \(x \in A\), define
  \begin{equation}
    g_x: B \to \reals, g_x(y) = f(x, y)
  \end{equation}
  Set
  \begin{equation}
    \mc{L}(x) = \loint_Bg_x = \loint_Bf(x, y)dy, \mc{U}(x) = \hiint_Bg_x = \hiint_Bf(x, y)dy
  \end{equation}
  Then \(\mc{L}(x), \mc{U}(x)\) are integrable on \(A\) and
  \begin{equation}
    \int_{A \times B}f = \int_A\mc{L} = \int_A\mc{U} = \int_A\left(\loint_Bf(x, y)dy\right)dx = \int_A\left(\hiint_Bf(x, y)dy\right)dx
  \end{equation}
\end{theorem}
Before we prove this, some remarks:
\begin{enumerate}

  \item We also have
  \begin{equation}
    \int_{A \times B}f = \int_B\left(\loint_A(f(x, y)dx)\right)dy = \int_B\left(\hiint_A(f(x, y)dx)\right)dy
  \end{equation}

  \item If \(g_x\) is integrable on \(B\) for every \(x \in A\), then
  \begin{equation}
    \int_{A \times B}f = \int_A\left(\int_Bf(x, y)dy\right)dx
  \end{equation}

  \item If
  \begin{equation}
    A = [a_1, b_1] \times [a_2, b_2] \times ... \times [a_n, b_n]
  \end{equation}
  we can apply Fubini's theorem repeatedly to obtain
  \begin{equation}
    \int_Af = \int_{a_n}^{b_n} \left(... \int_{a_2}^{b_2}\left(\int_{a_1}^{b_1}f(x_1,...,x_n)dx_1\right)dx_2...\right) dx_n
  \end{equation}
  if \(f\) is ``sufficiently nice'' (otherwise we'll have to sprinkle in some L's or U's).

\end{enumerate}

Now here's an application to \(\int_Cf\) when \(f\) is integrable on a Jordan-measurable set \(C \subset \reals^n\). What we're going to use is Fubini's theorem in a rectangle with the formula
\begin{equation}
  \int_Cf = \int_Af\indic{C}
\end{equation}
where \(A \supseteq C\) is a closed rectangle.
Let's do some quick examples:
\begin{enumerate}

\item Let's say we were integrating on the region
\begin{equation}
  C = [-1, 1] \times [-1, 1] \setminus \{x \in \reals^2, x_1^2 + x_2^2 < 1\}
\end{equation}
i.e. the unit square with the unit circle removed from it. We have
\begin{equation}
  \int_Cf = \int_{[-1, 1]^2}f\indic{C}
\end{equation}
We can write
\begin{equation}
  \indic{C} = \left\{\begin{array}{cc}
    1 & \text{if } -1 \leq y \leq -\sqrt{1 - x^2} \text{ or } \sqrt{1 - x^2} \leq y \leq 1 \\
    0 & \text{otherwise}
  \end{array}\right.
\end{equation}
We can write
\begin{equation}
  \int_{-1}^1f(x, y)\indic{C}(x, y)dy = \int_{-1}^{-\sqrt{1 - x^2}}f(x, y)dy + \int_{\sqrt{1 - x^2}}^1f(x, y)dy
\end{equation}
i.e. the limits of integration correspond to the boundary of \(C\). So we get
\begin{equation}
  \int_Cf = \int_{-1}^1\left(\int_{-1}^{-\sqrt{1 - x^2}}f(x, y)dy + \int_{\sqrt{1 - x^2}}^1f(x, y)dy\right)dx
\end{equation}

\item Say we want to integrate over a triangle \(C\), under the line from \((0, 0)\) to \((a, a)\). We have
\begin{equation}
  \int_Cf = \int_0^a\left(\int_y^af(x, y)dx\right)dy
\end{equation}
We could have done it the other way, integrating first with respect to \(y\) and then with respect to \(x\), and get
\begin{equation}
  \int_Cf = \int_0^a\left(\int_0^xf(x, y)dy\right)dx
\end{equation}
This shows the form might not be the same in different directions. And it could be important to exploit the difference. For example, what if our function \(f(x, y)\) only depends on one of the variables, say \(y\) (i.e. \(f\) is \textit{independent} of \(x\)). Then
\begin{equation}
  \int_0^a\left(\int_0^xf(y)dy\right)dx
\end{equation}
doesn't simplify very much, but
\begin{equation}
  \int_0^a\left(\int_y^af(y)dx\right)dy = \int_0^a(a - y)f(y)dy
\end{equation}
So this double integral reduces to a single integral with respect to \(y\).

\TODO{proof}

\TODO{polish}
Before we move on, we will give some more examples of computing integrals, using Fubini's theorem and the change of variables theorems as tools.

Let us begin by recalling some facts about the regions on whuch we can integrate. What are the kinds of region on which we integrate? One of the kinds of regions would be the region between the graphs of two functions that are defined on a Jordan-measurable set. Specifically, if we have a subset \(C \subset \reals^n\) that is Jordan-measurable, and two integrable functions \(\varphi(x) \leq \psi(x)\) defined on \(C\), we're interested in integrating over the region bounded by the graphs of the two functions Let's call this region \(S\), that is, define
\begin{equation}
  S = \{(x, y) \in \reals^n \times \reals : x \in C, y \in [\varphi(x), \psi(x)]\}
\end{equation}

We have that \(S\) is a Jordan-measurable set. We want to be able to integrate a continuous function on \(S\). If \(f(x, y)\) is a bounded continuous on \(S\), then we can compute using Fubini's theorem that
\begin{equation}
  \int_Sf = \int_C\left(\int_{\varphi(x)}^{\psi(x)}f(x, y)dy\right)dx
\end{equation}
We went through the proof of this before, but I want to use it to compute some examples.
\begin{enumerate}

  \item Consider
  \begin{equation}
    \int_0^2\int_{y/2}^1ye^{-x^3}dxdy
  \end{equation}
  There's no hope in proceeding naively, since \(e^{-x^3}\) doesn't even have an elementary primitive, i.e. you cannot write down it's integral with only elementary functions. But let's consider what region we're integrating along: the area under the line between \((0, 0)\) and \((2, 1)\). So using the above observation, we can rewrite the integral to be
  \begin{equation}
    \int_0^1\left(\int_0^{2x}ye^{-x^3}dy\right)dx = \int_0^1\left.\frac{y^2}{2}e^{-x^3}\right|_0^{2x}dx = 2\int_0^1x^2e^{-x^3}dx = \left.-\frac{2}{3}e^{-x^3}\right|_{0}^{1} = \frac{2}{3}(1 - e^{-1})
  \end{equation}
  Here, the change of variable was a useful thing to do, because it enabled us to write down an original integral, which we couldn't do in the original form.

  \item Consider
  \begin{equation}
    \int_2^4\int_{4/x}^{\frac{20 - 4x}{8 - x}}(y - 4)dydx
  \end{equation}
  So here, again, should we just go ahead and do it as it's written? Well then we'll get \(\frac{y^2}{2} - 4y\) and we'll substitute those things in and we'll just get a terrible mess. But what's the region we're integrating over? \(\frac{4}{x}\) is like a hyperbola, which is 2 when \(x\) is 2 and 1 when \(x\) is 4. The other function on top, what does it look like? It's also a hyperbola: it's a constant plus something over \(8 - x\), so it'll open down. And this is the region we're integrating on: the area between a hyperbola open up and another opening down.

  If we change the order of integration, we'll be integrating on the outside with respect to \(y\), which goes from 1 to 2, and we'll be integrating on the inside with respect to \(x\) with \(x\) going from \(4/y\) to... let's solve:
  \begin{equation}
    y = \frac{20 - 4x}{8 - x} = 4 + \frac{12}{x - 8} \implies x - 8 = \frac{12}{y - 4} \iff x = 8 + \frac{12}{y - 4}
  \end{equation}
  Hence we can write the above as
  \begin{equation}
    \int_1^2\left(\int_{4/y}^{8 + 12/(y - 4)}(y - 4)dx\right)dy = \left.\int_1^2(y - 4)x\right|_{4/y}^{8 + 12/(y - 4)}dy = \int_1^2(y - 4)\left(8 + \frac{12}{y - 4} - \frac{4}{y}\right)dy
  \end{equation}
  which is all stuff that's very easy to integrate

  \item Let's see how to integrate a simple function \(z\) over a region of \(3\)-space
  \begin{equation}
    S = \{(x, y, z) \in \reals^3 : x^2 + y^2 \leq z^2 \land x^2 + y^2 + z^2 \leq 1\}
  \end{equation}
  So, what is this region? The second equation says we're inside the closed ball of radius 1 centered at the origin. The first equation is the region inside two  cones, opening up and down from the origin (kind of like an hour glass). So we want the intersection of these two regions. In terms of the theorem that we wrote down at the beginning, the set \(C\) is like the discs inside the circles formed by the intersections of the top and bottom of the cones and circles, and we're integrating on the region between the semicircles above and below the plane, and the cones above and below the plane. So what's this going to be? Well, by symmetry, it's going to be \textit{zero}.

  Let's make it a little harder. Let's consider only the top, i.e.
  \[S^+ = \{(x, y, z) \in S : z \geq 0\}\]
  So, rewriting our integral to be over the disc \(C\), we obtain
  \begin{equation}
  \begin{split}
    \int\int_{x^2 + y^2 \leq \frac{1}{2}}\left(\int_{\sqrt{x^2 + y^2}}^{\sqrt{1 - (x^2 + y^2)}}zdz\right)dxdy \\
    = \int\int_{x^2 + y^2 \leq \frac{1}{2}}\frac{1}{2}(1 - (x^2 + y^2) - (x^2 + y^2))dxdy \\
    = \frac{1}{2}\int\int_{x^2 + y^2 \leq \frac{1}{2}}dxdy - \int\int_{x^2 + y^2 - \frac{1}{2}}(x^2 + y^2)dxdy = \frac{1}{2}\pi\frac{1}{2} = \frac{\pi}{4}
  \end{split}
  \end{equation}
  How do we justify that last, ``magical'' step? Well, the prettiest way to do so is to change to polar coordinates, but we haven't justified this quite yet, which is the point of this example. You'll remember from first year caclulus that we can write
  \begin{equation}
    \int_a^bf(g(x))g'(x)dx = \int_{g(a)}^{g(b)}f(u)du
    \label{firstyearsub}
  \end{equation}
  This is what we're going to be doing in several variables. But first: polar coordinates? That means writing
  \begin{equation}
    x = r\cos\theta, y = r\cos\theta, \theta \in [0, 2\pi], r \in [0, \infty)
  \end{equation}
  This gives that
  \begin{equation}
    \prt{(x, y)}{(r, \theta)} = \begin{pmatrix}\cos\theta & -r\sin\theta \\ \sin\theta & r\cos\theta\end{pmatrix} \implies \det\prt{(x, y)}{(r, \theta)} = r \implies dxdy = drd\theta
  \end{equation}
  ``generalizing'' equation \ref{firstyearsub}. On the other hand, we have that
  \begin{equation}
    x^2 + y^2 = r^2
  \end{equation}
  Since we have that, for this disc, \(\theta\) ranges over the whole interval \([0, 2\pi]\) whereas \(r\) ranges over \([0, 1/\sqrt{2}]\), we can hence rewrite the above integral as
  \begin{equation}
    \int_0^{2\pi}\int_0^{\frac{1}{\sqrt{2}}}r^2 \cdot rdrd\theta =
    \int_0^{2\pi}d\theta\int_0^{\frac{1}{\sqrt{2}}}r^3dr =
    \left.2\pi\frac{r^4}{4}\right|_{0}^{\frac{1}{\sqrt{2}}} = \frac{\pi}{8}
  \end{equation}

\end{enumerate}


\subsection{Partitions of Unity}


\subsubsection{Bump Functions}

A bump function, in the one dimensional case, is a function which goes up to 1 from 0, stays there for a while, and then returns to zero. But we're interested in doing this in \(n\)-dimensions. How? Given an open \(U \subset \reals^n\), and compact \(C \subset U\), we want to construct a \(\mc{C}^\infty\) function \(f: U \to \reals\) with \(0 \leq f \leq 1\) such that \(\forall x \in C, f(x) = 1\) and \(f(x) = 0\) outside some compact subset of \(U\). So it looks like the 1-dimensional bump function, except over an \(n\)-dimensional area \(C\).

How can we construct such a function? We'll do it as a kind of series of exercises, based on one particular function, which you can imagine ought to be the kind of thing that you have to build this function, that is,
\begin{equation}
  f(x) = \left\{\begin{array}{ccc}
    e^{1/x^2} & \text{if} & x \neq 0 \\
    0 & \text{if} & x = 0
  \end{array}\right.
  \label{bumpbuild}
\end{equation}
We proceed as follows, building up by steps:
\begin{enumerate}

  \item There is a \(\mc{C}^\infty\) function \(g: \reals \to \reals\) such that \(g > 0\) on \((-1, 1)\), 0 elsewhere. It's easy to write down a formula for such a function using the function given in \ref{bumpbuild}, as follows:
  \begin{equation}
    g(x) = \left\{\begin{array}{ccc}
      e^{-\frac{1}{(x - 1)^2}}e^{-\frac{1}{(x + 1)^2}} & \text{if} & x \in (-1, 1) \\
      0 & \text{if} & x \notin (-1, 1)
    \end{array}\right.
    \label{g}
  \end{equation}
  This works because \(e^{-\frac{1}{(x - 1)^2}}\) becomes completely flat at \(x = 1\), whereas \(e^{-\frac{1}{(x + 1)^2}}\) becomes completely flat at \(x = -1\).

  \item Given \(a \in \reals^n, \delta > 0\), there is a \(C^\infty\) function \(g_{a, \delta}: \reals^n \to \reals\) such that
  \begin{equation}
    g_{a, \delta} > 0 \text{ on } |x - a| < \delta, g_{a, \delta} = 0 \text{ outside}
  \end{equation}
  So how could achieve this? We could use the function defined in \ref{g} to write
  \begin{equation}
    g_{a, \delta} = g\left(\frac{|x - a|^2}{\delta^2}\right)
  \end{equation}

  \item There is a \(\mc{C}^\infty\) function \(h: U \to \reals\) such that \(h\) is greater than 0 on \(C\) and \(h = 0\) outside a compact subset of \(U\). So how do we do this?

  We could cover \(C\) with a finite set of open balls \(U_1,...,U_k\) with centers \(a_1,...,a_k\) and radii \(\delta_1,...,\delta_k\) whose closures lie in \(U\). We can do this since \(C\) is compact. Once we do this, we can define quite simply
  \begin{equation}
    h(x) = \sum_{i = 1}^kg_{a_k, \delta_k}(x)
    \label{compactsum}
  \end{equation}

  \item As a fourth thing, going back to the real line, let's show that if we're given any \(\epsilon \in \reals^+\), we can find a \(\mc{C}^\infty\) function \(\psi_\epsilon\) which is zero up to 0, becomes 1 at \(\epsilon\), and then remains 1 forever after. How can we do this from what we've already done? We're going to do it starting with a \(\mc{C}^\infty\) function like that in equation \ref{g}, but instead of on \((-1, 1)\), on \((0, \epsilon)\). More generally, actually, we can use any function \(g\) such that \(g > 0\) on \((0, \epsilon)\) and is zero outside. We can then define \(\psi_\epsilon\) by
  \begin{equation}
    \psi_\epsilon(x) = \frac{\int_0^xg}{\int_0^\epsilon g}
    \label{riseup}
  \end{equation}

  \item Now, putting everything together, how can we define the bump function that we wanted to begin with? We begin with the function \(h\) as defined in equation \ref{compactsum}, and we're going to modify it using equation \ref{riseup} as follows: letting \(\epsilon = \min_Ch > 0\), which exists since \(C\) is compact, let
  \begin{equation}
    f(x) = \psi_\epsilon \circ h
  \end{equation}

\end{enumerate}

Now there are other ways of doing it. One of them is to write down one integral formula from the beginning, but it would be harderto see just where this formula comes from in the first place. We can now get to defining partitions of unity:
\begin{theorem}
  Given \(A \subset \reals^n\) and an open cover \(\mc{O}\) of \(A\), there is a countable collection \(\Phi\) of \(\mc{C}^\infty\) functions \(\varphi\) on \(\reals^n\) with the following properties:
  \begin{enumerate}

    \item \(0 \leq \varphi \leq 1\)

    \item For all \(x \in A\), there is an open neighborhood \(V_x\) of \(x\) in \(\reals^n\) such that all but finitely many \(\varphi\) vanish on \(V_x\)

    \item For all \(x \in A\), \(\sum_{\varphi \in \Phi}\varphi(x) = 1\) (sum is finite in a neighborhood of \(x\))

    \item For all \(\varphi in \Phi\), there is some open \(U \in \mc{O}\) such that \(\varphi = 0\) outside a compact subset of \(U\).

  \end{enumerate}
\end{theorem}
\begin{definition}
  A collection \(\varphi\) satisfying (1),(2),(3) above is called a \underline{\(\mc{C}^\infty\) partition for \(A\)}. If (4) holds, this partition is called \underline{subordinate to \(\mc{O}\)}
\end{definition}
This is all \(\mc{C}^\infty\) stuff, but we could have made something weaker. We could have asked for a \(\mc{C}^r\) partition, or even a partition that was merely continous. So suppose we did that, and only cared about a \(\mc{C}^0\) partition. Then, we could also, though the proof will have to come next time, we could use functions that look like trapezoids, using \(|x|\) instead of \(e^{-\frac{1}{x^2}}\). If we wanted a \(\mc{C}^r\) partition of unity, then of course, we could do the same thing, but only caring about \(\mc{C}^r\) instead of \(\mc{C}^\infty\), and hence using the function given by
\begin{equation}
  f(x) = \left\{\begin{array}{ccc}
    |x^{r + 1}| & \text{on} & [0, \infty) \\
    -|x^{r + 1}| & \text{on} & (-\infty, 0]
  \end{array}\right.
\end{equation}


\TODO{rest}

\subsection{Change of Variables}

\TODO{this}

\subsection{Parametrically Defined Curves}

\TODO{this}

\section{Manifolds}

\subsection{What is a manifold?}

\TODO{this}

\subsection{Functions Between Manifolds}

\TODO{this}

\subsection{Manifolds with Boundary}

\TODO{this}

\subsection{Multilinear Algebra}

\TODO{this}

\subsection{Vector Fields and Differential Forms}

\TODO{this}

\subsection{The Differential Operator}

\TODO{this}

\section{Integration on Manifolds}

\TODO{this}

\subsection{Integration of Parametrized Curves}

\TODO{this}

\subsection{Integral of a \(k\)-form over a \(k\)-cube}

\TODO{this}

\subsection{Integration of Differential Forms on Manifolds}

\TODO{this}

\subsection{Manifolds with Boundary}

\TODO{this}

\subsection{Stoke's Theorem on Manifolds}

\TODO{this}

\end{document}
